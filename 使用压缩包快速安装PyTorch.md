**这是草稿，具体的在https://halo.gcnanmu3125.xyz/archives/%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85pytorch**
# 快速压缩包快速安装PyTorch

## 一、写在前面

---

> PyTorch官网：https://pytorch.org/

在Windows环境下，PyTorch的安装由于网络问题，大部分人如果想直接通过官网的指令安装显然是非常困难的。因为torch这个库有2G左右的大小，服务器又在国外，这就出现了下载异常缓慢（能下一天）或者下载容易失败的问题（网络问题导致下载中断）。

这时候有两种方法：

1. 使用魔法，改善下载速度。
2. 使用本地文件安装。

这个博客主要记录如何使用本地压缩包（.whl）文件快速安装PyTorch。

## 二、明确自己的使用需求

---

如果你需要使用GPU进行PyTorch实践，那么你就需要安装带CUDA的版本。如果你只是想要使用CPU进行实践，那么就选择CPU版本进行下载。各有优势，没有高低之分。

## 三、查看自己的CUDA版本并安装CUDA支持

---

如果下载CUDA版本的PyTorch，此时就需要对应自己电脑所支持的最高CUDA版本，然后同级或者向下兼容选择相应的CUDA安装指令。查看CUDA版本有两种方法。

1. 通过NVIDIA控制面板

   

2. 通过指令

   打开命令行，输入`nvidia-smi`，出现以下界面

## 四、选择安装方式

---

如果你是Windows用户，一般情况下，官网提供了两种常用的安装方式：

1. pip指令
2. Conda指令（需要Anaconda环境）

这两个指令下载的东西都是一样的，只是安装的方式不同。建议在Anaconda环境中安装，方便管理。

## 五、下载离线文件

---

.whl文件，实际就是torch的压缩文件，当我们使用pip进行库的下载时候，先拉取压缩包请求，然后在本地解压安装。这边有个注意点，如果当前拉取的压缩包已经存在，则会直接解压。所以我们提前准备好torch的压缩包，当使用pip指令下载时，会直接拉取本地的压缩包，跳过下载安装包的过程。从本地文件安装的原理就是如此。

* 当然还有一个重要前提，单独下载.whl文件真的非常快。

下载文件之前需要了解一些概念，以`torch-1.12.0+cu116-cp37-cp37m-win_amd64.whl`这个文件名为例。

>torch-1.12.0：代表torch版本
>
>cu116：代表支持CUDA11.6
>
>cp37：代表运行环境为Python3.7
>
>win：指Windows平台
>
>amd64：代表64位操作系统

了解这些之后就可以按自己的需求下载自己需要的.whl压缩文件。

> 下载地址：https://download.pytorch.org/whl/torch/

* 小提示：善用快捷搜索，Ctrl+F
* 下载后的文件最好放入`C:\Users\用户名`路径下，方便后续安装。

## 六、使用pip指令安装压缩文件

---

以`torch-1.12.0+cu116-cp37-cp37m-win_amd64.whl`为例。

进入要安装的环境命令行，进入.whl文件所在的路径，运行指令`pip install torch-1.12.0+cu116-cp37-cp37m-win_amd64.whl ` 

如果没出现下载，就会自动显示要求满足，然后压缩安装。如果还是下载了，请自行关闭命令行再次尝试一遍。

安装torch完成后，打开官网再次运行安装命令安装其他相适应的库即可，此时就会直接跳过torch的安装了。

## 七、一些检查指令

---

* 返回当前设备索引
  `torch.cuda.current_device()`
* 返回GPU的数量
  `torch.cuda.device_count()`
* 返回gpu名字，设备索引默认从0开始
  `torch.cuda.get_device_name(0)`
* cuda是否可用
  `torch.cuda.is_available()`

我的结果：

